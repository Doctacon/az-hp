---
"id": "ah-0094"
"status": "closed"
"deps": []
"links": []
"created": "2026-02-17T18:56:57Z"
"type": "task"
"priority": 1
"assignee": "Connor"
"parent": "ah-1494"
"tags":
- "sprint:fix-make-all"
"external": {}
---
# Download missing Overture places data

# Download missing Overture places data

## Objective Alignment
The places data is required for the enrich step to filter hunt-relevant POIs. Without it, \`03_enrich.py\` will fail.

## Problem
The file \`data/raw/overture_places_az.parquet\` doesn't exist because:
1. The download script (\`01_download.py\`) never reached this step
2. It comes after buildings in the download order, and buildings download likely timed out

## Scope
- Ensure \`data/raw/overture_places_az.parquet\` is downloaded successfully
- May need to increase timeout or run download in isolation

## Non-goals
- Fix buildings download (separate investigation)
- Modify the download script architecture

## Implementation Plan

Option A: Re-run just the places download
\`\`\`bash
uv run python -c "
import sys
from pathlib import Path
sys.path.insert(0, str(Path('.').absolute()))
from pipeline.01_download import download_overture_places
download_overture_places()
"
\`\`\`

Option B: If Option A times out, increase the AZ_BBOX query selectivity or use a more specific query

## Acceptance Criteria
- [ ] \`data/raw/overture_places_az.parquet\` exists
- [ ] File has > 0 bytes
- [ ] File is readable as parquet

## Verification Commands
\`\`\`bash
# Check file exists and size
ls -la data/raw/overture_places_az.parquet

# Verify it's readable
uv run python -c "
import geopandas as gpd
gdf = gpd.read_parquet('data/raw/overture_places_az.parquet')
print(f'Loaded {len(gdf)} places')
"
\`\`\`

## Risks/Edge Cases
- Download may timeout like buildings did
- If timeout, need to investigate Overture API query optimization

## Acceptance Criteria

data/raw/overture_places_az.parquet exists and has >0 bytes

## Notes

**2026-02-17T19:04:19Z**

Successfully downloaded Overture places data using importlib to load the 01_download.py module. File size: 22.7 MB with 313,864 places. All acceptance criteria met.

**2026-02-17T19:05:19Z**

## Verification Complete

**All acceptance criteria met:**
- ✅ data/raw/overture_places_az.parquet exists
- ✅ File has 22,715,730 bytes (~22.7 MB)
- ✅ File is readable as parquet: 313,864 places loaded

**Commands run:**
```bash
# Download using importlib (module name has numeric prefix)
uv run python -c "
import importlib.util
spec = importlib.util.spec_from_file_location('download', 'pipeline/01_download.py')
module = importlib.util.module_from_spec(spec)
spec.loader.exec_module(module)
module.download_overture_places()
"

# Verify
ls -la data/raw/overture_places_az.parquet
uv run python -c "
import geopandas as gpd
gdf = gpd.read_parquet('data/raw/overture_places_az.parquet')
print(f'Loaded {len(gdf)} places')
"
```

**Risks:** None identified. Download completed successfully in ~8 minutes.

**2026-02-17T19:05:39Z**

## Verification Complete

**All acceptance criteria met:**
- data/raw/overture_places_az.parquet exists (22.7 MB)
- File readable as parquet: 313,864 places loaded
- Columns: id, geometry, names, categories, confidence

**Solution:** Used importlib to load 01_download.py since module name starts with number.

**No code changes needed** - data files are gitignored per project design.
