---
"id": "ah-1557"
"status": "in_progress"
"deps": []
"links": []
"created": "2026-02-17T17:06:56Z"
"type": "task"
"priority": 1
"assignee": "Connor"
"tags":
- "sprint:build-pipeline"
- "fanout"
"external": {}
---
# Sprint prep: build-pipeline

Objective:
Build the application after reading status.md

Sprint prep deliverable (fill this ticket in, then create tickets):

## Sprint Brief

### Objective Restatement

Build the AZ Hunt Planner web application by making the data pipeline run end-to-end, from raw data download through tile generation, so the frontend can display real geographic data for Arizona hunting units, land ownership, roads, water features, and POIs.

### Sprint Focus (4 words)

**Fix pipeline, ship tiles**

### Why This Sprint Focus Is the Best Next Step

The STATUS.md reveals that while scaffolding and frontend code are complete, the data pipeline is blocked at multiple points:
1. **Clip step times out** on large layers (buildings/places with 422MB/22MB)
2. **BLM SMA data is incomplete** — missing BLM and State Trust land, the two most critical land types for hunting access
3. **Enrich step can't run** — blocked on missing clipped outputs
4. **No tiles exist** — nothing for the frontend to display

Fixing the pipeline unlocks everything. Once we have tiles, we can test the frontend and iterate. The alternative (fixing BLM data first) doesn't unblock the pipeline — we can ship with incomplete BLM data and improve later.

### Current State

**Existing Tickets That Matter:**
- \`ah-04fc\` — solve status.md items and make this web application (open, P1) — this is the parent objective

**Codebase State:**
- Git: clean working tree on branch \`team/ah-1557\`, only 4 commits total
- Data: \`data/\` directory does NOT exist — clean slate, needs to be created
- Pipeline scripts: exist but untested end-to-end
  - \`pipeline/01_download.py\` — works, BLM layer 7/14 errors handled gracefully
  - \`pipeline/02_clip_arizona.py\` — times out on buildings/places (uses slow GeoPandas \`clip\`)
  - \`pipeline/03_enrich.py\` — untested, depends on clipped output
  - \`pipeline/04_generate_tiles.sh\` — untested, depends on enrich output
- Frontend: code complete, builds successfully, untested with real data
  - React + Vite + MapLibre + PMTiles
  - Expects files in \`frontend/public/data/\`

**Data Inventory (from STATUS.md):**
- Raw data exists (downloaded previously) but processed data is incomplete
- Missing: \`overture_buildings_clipped.parquet\`, \`overture_places_clipped.parquet\`
- Missing: \`roads_enriched.parquet\`, \`places_hunt.parquet\`
- Missing: all PMTiles

### Risks + Unknowns (and How We'll Resolve Them)

| Risk | Resolution |
|------|------------|
| Clip still slow even with DuckDB | Skip buildings/places clip; use bbox-filtered data directly |
| BLM SMA BLM/State layers still fail | Proceed without; use existing 64 features (NPS/FWS/DOD/FS/USBR); document gap |
| Tile generation fails on large files | Use tippecanoe drop/coalesce options; may need to simplify geometries |
| Frontend doesn't render PMTiles | Debug with browser console; check PMTiles protocol registration |
| No test data locally | Run \`make download\` first to populate \`data/raw/\` |

### Plan Overview

1. **Create data directories** — ensure \`data/{raw,processed,tiles}\` and \`frontend/public/data/\` exist
2. **Run data download** — populate \`data/raw/\` with all Overture + AZ boundary + GMU + partial BLM
3. **Fix clip for large layers** — switch buildings/places to DuckDB spatial or skip clip entirely
4. **Run enrich** — spatial joins for roads x land x GMUs, filter hunt-relevant POIs
5. **Generate tiles** — tippecanoe to PMTiles, copy to frontend
6. **Test frontend** — run dev server, verify layers render
7. **Commit working code** — first real commit with working pipeline

### Suggested Ordering + Parallelization

\`\`\`
[T1: Setup dirs] ─┬─> [T2: Download] ─┬─> [T4: Enrich] ─> [T5: Tiles] ─> [T6: Test frontend]
                  │                    │
                  └─> [T3: Fix clip] ──┘
\`\`\`

- T1 can run immediately (no deps)
- T2 and T3 can start after T1
- T4 depends on T2 AND T3
- T5 depends on T4
- T6 depends on T5
- T7 (commit) after T6

---

## Ticket Set

Create the sprint tickets directly. This sprint prep ticket should be the parent.
- Tag rule: include \`sprint:build-pipeline\` on sprint tickets.
- Prefer: \`loom ticket create ... --parent <THIS_TICKET_ID> --acceptance "...\`

Ticket quality rubric (non-negotiable):
- Scope + explicit non-goals
- Step-by-step implementation plan (include file paths when possible)
- Acceptance criteria (observable outcomes)
- Verification commands (use \`uv run ...\` for Python)
- Risks/edge cases
- Dependencies + suggested ordering (use \`loom ticket dep-add\`)

## Output

When done, update THIS ticket with:
- Created/updated ticket IDs: [ ... ]
- Suggested ordering + what can run in parallel

Sprint name: build-pipeline
Sprint tag: sprint:build-pipeline

## Notes

**2026-02-17T17:17:33Z**

## Sprint Tickets Created

| ID | Title | Dependencies | Parallel With |
|----|-------|--------------|---------------|
| ah-6760 | Setup data directories | None | Starts first |
| ah-cc7e | Run data download pipeline | ah-6760 | ah-d2c5 |
| ah-d2c5 | Fix clip for large layers | ah-6760 | ah-cc7e |
| ah-ce83 | Run enrichment pipeline | ah-cc7e, ah-d2c5 | None |
| ah-6cab | Generate PMTiles | ah-ce83 | None |
| ah-d2e1 | Test frontend with real data | ah-6cab | None |

## Suggested Ordering + Parallelization

```
[T1: ah-6760 Setup] ─┬─> [T2: ah-cc7e Download] ─┬─> [T4: ah-ce83 Enrich] ─> [T5: ah-6cab Tiles] ─> [T6: ah-d2e1 Test]
                     │                           │
                     └─> [T3: ah-d2c5 Fix clip] ─┘
```

**Parallel opportunities:**
- T2 (Download) and T3 (Fix clip) can run in parallel after T1 completes
- All other steps are sequential

**Critical path:** T1 → T2 → T4 → T5 → T6 (assuming T2 finishes before T3)

**Estimated time:**
- T1: 5 minutes
- T2: 30-60 minutes (network-bound)
- T3: 10 minutes (code change + run)
- T4: 10-20 minutes (spatial joins)
- T5: 10-20 minutes (tile generation)
- T6: 10 minutes (manual testing)

**Total: ~75-125 minutes** (can be faster with parallel execution)
