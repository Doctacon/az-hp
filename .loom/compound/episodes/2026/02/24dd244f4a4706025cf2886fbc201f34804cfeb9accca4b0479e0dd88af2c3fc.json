{
  "created_at": "2026-02-20T21:52:32.190519Z",
  "episode_id": "24dd244f4a4706025cf2886fbc201f34804cfeb9accca4b0479e0dd88af2c3fc",
  "git": {
    "base_ref": "origin/main",
    "base_sha": "12fa54d6612b9850af96591a8b72f9a7375bccaf",
    "changed_files": [
      ".loom/compound/INSTINCTS.md",
      ".loom/compound/instincts.json",
      "Makefile",
      "frontend/package-lock.json",
      "frontend/package.json",
      "frontend/src/App.jsx",
      "frontend/src/components/LayerPanel.jsx",
      "pipeline/01_download.py",
      "pipeline/02_clip_arizona.py",
      "pipeline/03_enrich.py",
      "pipeline/04_generate_tiles.sh"
    ],
    "diffstat": ".loom/compound/INSTINCTS.md            |  62 ++++-\n .loom/compound/instincts.json          | 462 ++++++++++++++++++++++++++++++++-\n Makefile                               |  13 +-\n frontend/package-lock.json             |  10 +\n frontend/package.json                  |   1 +\n frontend/src/App.jsx                   | 307 +---------------------\n frontend/src/components/LayerPanel.jsx |   3 -\n pipeline/01_download.py                | 124 +++------\n pipeline/02_clip_arizona.py            |  14 +-\n pipeline/03_enrich.py                  |  16 +-\n pipeline/04_generate_tiles.sh          | 156 +++++------\n 11 files changed, 686 insertions(+), 482 deletions(-)",
    "diffstat_sha256": "5fa71d65678c0fd4453478ed9600088583fafead31967d326f8bcf0e3a11b11c",
    "dirty": true,
    "head_sha": "12fa54d6612b9850af96591a8b72f9a7375bccaf",
    "patch": "diff --git a/.loom/compound/INSTINCTS.md b/.loom/compound/INSTINCTS.md\nindex b01982a..0485bf6 100644\n--- a/.loom/compound/INSTINCTS.md\n+++ b/.loom/compound/INSTINCTS.md\n@@ -1,5 +1,65 @@\n # INSTINCTS\n \n <!-- BEGIN:compound:instincts-md -->\n-(autogenerated)\n+## Active instincts (top confidence)\n+\n+- **react-hook-extraction** (85%) [frontend, react, refactoring]\n+  - Trigger: When a React component file exceeds ~200 lines with mixed concerns (state, effects, event handlers, rendering)\n+  - Action: Extract logical groups into custom hooks (e.g., useMapSources, useMapLayers, useMapInteractions) with a barrel index.js export. Keep the main component as a thin composition layer.\n+- **barrel-export-hooks** (80%) [frontend, imports, react]\n+  - Trigger: When creating multiple custom hooks in a hooks/ directory\n+  - Action: Create an index.js barrel file that re-exports all hooks, enabling clean imports like `import { useMap, useMapSources } from './hooks'`\n+- **instincts-json-sync** (80%) [compound, loom, memory]\n+  - Trigger: When updating instincts or compound memory\n+  - Action: Both .loom/compound/instincts.json and .loom/compound/INSTINCTS.md must be updated together. The JSON is the source of truth; the MD is the human-readable view.\n+- **az-hp-frontend-component-extraction** (75%) [components, frontend, react]\n+  - Trigger: When App.jsx or any single component file exceeds ~150 lines\n+  - Action: Extract logical sections into separate component files under frontend/src/components/ to keep the main App.jsx focused on layout and routing\n+- **frontend-component-extraction** (75%) [frontend, react, refactoring]\n+  - Trigger: When App.jsx or any single component exceeds ~200 lines\n+  - Action: Extract logical sections into dedicated component files under frontend/src/components/. The project already follows this pattern (e.g., LayerPanel.jsx).\n+- **makefile-pipeline-targets** (75%) [devops, makefile, pipeline]\n+  - Trigger: When adding new pipeline scripts\n+  - Action: Add corresponding Makefile targets so the full pipeline can be run via make commands. Keep targets composable and ordered.\n+- **az-hp-makefile-pipeline** (70%) [az-hp, makefile, pipeline]\n+  - Trigger: When working on the az-hp project pipeline (enrichment, tile generation, etc.)\n+  - Action: Check the Makefile for existing targets before creating new scripts. Pipeline steps are orchestrated via Make targets.\n+- **az-hp-pipeline-shell-scripts** (70%) [bash, error-handling, pipeline]\n+  - Trigger: When editing or creating shell scripts in the pipeline/ directory\n+  - Action: Always include `set -euo pipefail` at the top of bash scripts and use proper error handling with trap statements\n+- **az-hp-tile-generation-gdal** (70%) [gdal, geospatial, pipeline, tiles]\n+  - Trigger: When working on map tile generation or the 04_generate_tiles.sh script\n+  - Action: Use gdal2tiles.py or gdal_translate for raster tile generation; check that GDAL is available in the environment and handle missing dependencies gracefully\n+- **makefile-pipeline-orchestration** (70%) [make, orchestration, pipeline]\n+  - Trigger: When running or modifying the data pipeline\n+  - Action: Use `make` targets to run pipeline steps. Check the Makefile for available targets and their dependencies before running pipeline scripts directly.\n+- **az-hp-makefile-targets** (65%) [makefile, orchestration, pipeline]\n+  - Trigger: When running pipeline steps or adding new pipeline stages\n+  - Action: Add or update Makefile targets rather than running pipeline scripts directly; the Makefile serves as the orchestration layer for the data pipeline\n+- **tile-generation-pipeline** (65%) [geospatial, pipeline, tiles]\n+  - Trigger: When working with the map tile generation step of the pipeline\n+  - Action: Check pipeline/04_generate_tiles.sh for tile generation logic. This is a standalone bash script, not part of the Python pipeline scripts.\n+- **az-hp-frontend-jsx-pattern** (60%) [conventions, frontend, react]\n+  - Trigger: When working on frontend components in frontend/src/\n+  - Action: Use .jsx file extensions and plain JavaScript React patterns, not TypeScript. The project uses App.jsx as the main entry point.\n+- **az-hp-frontend-react-maplibre** (60%) [az-hp, frontend, maplibre, react]\n+  - Trigger: When modifying the az-hp frontend or working with map components\n+  - Action: The frontend is in frontend/ and uses React (App.jsx) with components like LayerPanel.jsx. Check frontend/package.json for dependencies. The app likely uses MapLibre GL for map rendering given the til...\n+- **az-hp-tile-generation** (60%) [az-hp, geospatial, pipeline]\n+  - Trigger: When working with the az-hp geospatial pipeline, specifically tile generation steps\n+  - Action: Check pipeline/04_generate_tiles.sh for the tile generation workflow. This project uses a numbered pipeline script convention (01_, 02_, 03_, 04_) in the pipeline/ directory.\n+- **az-hp-tile-generation-pipeline** (60%) [az-hp, geospatial, pipeline]\n+  - Trigger: When working with the az-hp map tile pipeline or modifying geographic data processing\n+  - Action: Check pipeline/04_generate_tiles.sh for tile generation logic. The pipeline follows a numbered sequence: 03_enrich.py -> 04_generate_tiles.sh.\n+- **tippecanoe-tile-generation** (60%) [az-hp, pipeline, tiles, tippecanoe]\n+  - Trigger: When generating map tiles from GeoJSON in the az-hp project\n+  - Action: Use the 04_generate_tiles.sh script which wraps tippecanoe. Check pipeline/04_generate_tiles.sh for the current tippecanoe flags and layer configuration.\n+- **az-hp-frontend-jsx-react** (55%) [az-hp, frontend, react]\n+  - Trigger: When editing the az-hp frontend UI\n+  - Action: The frontend entry point is frontend/src/App.jsx. Use React/JSX conventions when modifying components.\n+\n+## Notes\n+\n+- Instincts are the pre-skill layer: small, repeatable heuristics.\n+- When an instinct proves useful across sessions, promote it into a Skill.\n <!-- END:compound:instincts-md -->\ndiff --git a/.loom/compound/instincts.json b/.loom/compound/instincts.json\nindex 10c7d29..6c6ab02 100644\n--- a/.loom/compound/instincts.json\n+++ b/.loom/compound/instincts.json\n@@ -1,4 +1,464 @@\n {\n   \"version\": 1,\n-  \"instincts\": []\n+  \"instincts\": [\n+    {\n+      \"id\": \"az-hp-frontend-component-extraction\",\n+      \"title\": \"Extract large JSX into separate component files\",\n+      \"trigger\": \"When App.jsx or any single component file exceeds ~150 lines\",\n+      \"action\": \"Extract logical sections into separate component files under frontend/src/components/ to keep the main App.jsx focused on layout and routing\",\n+      \"tags\": [\n+        \"components\",\n+        \"frontend\",\n+        \"react\"\n+      ],\n+      \"confidence\": 0.75,\n+      \"status\": \"active\",\n+      \"created_at\": \"2026-02-20T14:43:30.991132Z\",\n+      \"updated_at\": \"2026-02-20T21:52:31.545973Z\",\n+      \"evidence\": [\n+        {\n+          \"ts\": \"2026-02-20T14:43:30.991132Z\",\n+          \"episode_id\": \"6b6ddb5ee674510280b27ef5ec0fd1ea952bd37fe5219b20a401436cc49b330a\",\n+          \"head_sha\": \"12fa54d6612b9850af96591a8b72f9a7375bccaf\",\n+          \"patch_sha256\": \"51418058b65060d53f0aef79cf9093151c3053e71eefe5dc9e979c8dfd5ea404\"\n+        },\n+        {\n+          \"ts\": \"2026-02-20T14:50:56.251832Z\",\n+          \"episode_id\": \"e4921c461a96610218c0dd59e32ddd4183f786d1488fb7fabc5343ed65246ec5\",\n+          \"head_sha\": \"12fa54d6612b9850af96591a8b72f9a7375bccaf\",\n+          \"patch_sha256\": \"aa853ee3cda8b401fa071cca9c6dd339149226a29c6eea408fe795e6b30fa799\"\n+        },\n+        {\n+          \"ts\": \"2026-02-20T21:52:31.545973Z\",\n+          \"episode_id\": \"6992ef1d173f95de9b9b407d46c0060ff0c5d2e72bcff50875f1bcc10cafe0cb\",\n+          \"head_sha\": \"12fa54d6612b9850af96591a8b72f9a7375bccaf\",\n+          \"patch_sha256\": \"82da319959d61f024ea6fed3ac7f24578e76fda777db1919074a6166498c2463\"\n+        }\n+      ]\n+    },\n+    {\n+      \"id\": \"az-hp-frontend-jsx-pattern\",\n+      \"title\": \"Frontend uses JSX with React (not TypeScript)\",\n+      \"trigger\": \"When working on frontend components in frontend/src/\",\n+      \"action\": \"Use .jsx file extensions and plain JavaScript React patterns, not TypeScript. The project uses App.jsx as the main entry point.\",\n+      \"tags\": [\n+        \"conventions\",\n+        \"frontend\",\n+        \"react\"\n+      ],\n+      \"confidence\": 0.6,\n+      \"status\": \"active\",\n+      \"created_at\": \"2026-02-20T00:51:17.517461Z\",\n+      \"updated_at\": \"2026-02-20T00:51:17.517461Z\",\n+      \"evidence\": [\n+        {\n+          \"ts\": \"2026-02-20T00:51:17.517461Z\",\n+          \"episode_id\": \"15e93a4c051522121a704e00ec72f8f276e3f477729fbf7d20005cc42eb7bb38\",\n+          \"head_sha\": \"12fa54d6612b9850af96591a8b72f9a7375bccaf\",\n+          \"patch_sha256\": \"e96515a87eac152e3942d8edf48c8f500e115709082ba6166bdfa1e04ac56ca5\"\n+        }\n+      ]\n+    },\n+    {\n+      \"id\": \"az-hp-frontend-jsx-react\",\n+      \"title\": \"Frontend uses JSX with React\",\n+      \"trigger\": \"When editing the az-hp frontend UI\",\n+      \"action\": \"The frontend entry point is frontend/src/App.jsx. Use React/JSX conventions when modifying components.\",\n+      \"tags\": [\n+        \"az-hp\",\n+        \"frontend\",\n+        \"react\"\n+      ],\n+      \"confidence\": 0.55,\n+      \"status\": \"active\",\n+      \"created_at\": \"2026-02-20T01:03:53.462206Z\",\n+      \"updated_at\": \"2026-02-20T01:03:53.462206Z\",\n+      \"evidence\": [\n+        {\n+          \"ts\": \"2026-02-20T01:03:53.462206Z\",\n+          \"episode_id\": \"08ab15196f535be35da63fa994005d24321037f7926984f9b793966ac7cd117a\",\n+          \"head_sha\": \"12fa54d6612b9850af96591a8b72f9a7375bccaf\",\n+          \"patch_sha256\": \"1d4114763a3cf8de38717b31d0ac30627dbfc7fac9b851a7985b5f6169ef6b99\"\n+        }\n+      ]\n+    },\n+    {\n+      \"id\": \"az-hp-frontend-react-maplibre\",\n+      \"title\": \"az-hp frontend uses React with MapLibre\",\n+      \"trigger\": \"When modifying the az-hp frontend or working with map components\",\n+      \"action\": \"The frontend is in frontend/ and uses React (App.jsx) with components like LayerPanel.jsx. Check frontend/package.json for dependencies. The app likely uses MapLibre GL for map rendering given the tile pipeline.\",\n+      \"tags\": [\n+        \"az-hp\",\n+        \"frontend\",\n+        \"maplibre\",\n+        \"react\"\n+      ],\n+      \"confidence\": 0.6,\n+      \"status\": \"active\",\n+      \"created_at\": \"2026-02-20T01:14:48.387480Z\",\n+      \"updated_at\": \"2026-02-20T01:14:48.387480Z\",\n+      \"evidence\": [\n+        {\n+          \"ts\": \"2026-02-20T01:14:48.387480Z\",\n+          \"episode_id\": \"aea43799649d4b3101aa55ac43b3f08ef3ae7614cb3d7ee49ced14feea17a5af\",\n+          \"head_sha\": \"12fa54d6612b9850af96591a8b72f9a7375bccaf\",\n+          \"patch_sha256\": \"7d86d1f664818b41827da0cd59f0678661a7a132179af312dd5b1c9a6268e0ac\"\n+        }\n+      ]\n+    },\n+    {\n+      \"id\": \"az-hp-makefile-pipeline\",\n+      \"title\": \"Use Makefile for pipeline orchestration\",\n+      \"trigger\": \"When working on the az-hp project pipeline (enrichment, tile generation, etc.)\",\n+      \"action\": \"Check the Makefile for existing targets before creating new scripts. Pipeline steps are orchestrated via Make targets.\",\n+      \"tags\": [\n+        \"az-hp\",\n+        \"makefile\",\n+        \"pipeline\"\n+      ],\n+      \"confidence\": 0.7,\n+      \"status\": \"active\",\n+      \"created_at\": \"2026-02-20T14:50:56.251832Z\",\n+      \"updated_at\": \"2026-02-20T14:50:56.251832Z\",\n+      \"evidence\": [\n+        {\n+          \"ts\": \"2026-02-20T14:50:56.251832Z\",\n+          \"episode_id\": \"e4921c461a96610218c0dd59e32ddd4183f786d1488fb7fabc5343ed65246ec5\",\n+          \"head_sha\": \"12fa54d6612b9850af96591a8b72f9a7375bccaf\",\n+          \"patch_sha256\": \"aa853ee3cda8b401fa071cca9c6dd339149226a29c6eea408fe795e6b30fa799\"\n+        }\n+      ]\n+    },\n+    {\n+      \"id\": \"az-hp-makefile-targets\",\n+      \"title\": \"Use Makefile targets for pipeline orchestration\",\n+      \"trigger\": \"When running pipeline steps or adding new pipeline stages\",\n+      \"action\": \"Add or update Makefile targets rather than running pipeline scripts directly; the Makefile serves as the orchestration layer for the data pipeline\",\n+      \"tags\": [\n+        \"makefile\",\n+        \"orchestration\",\n+        \"pipeline\"\n+      ],\n+      \"confidence\": 0.65,\n+      \"status\": \"active\",\n+      \"created_at\": \"2026-02-20T01:14:48.387480Z\",\n+      \"updated_at\": \"2026-02-20T21:52:31.545973Z\",\n+      \"evidence\": [\n+        {\n+          \"ts\": \"2026-02-20T01:14:48.387480Z\",\n+          \"episode_id\": \"aea43799649d4b3101aa55ac43b3f08ef3ae7614cb3d7ee49ced14feea17a5af\",\n+          \"head_sha\": \"12fa54d6612b9850af96591a8b72f9a7375bccaf\",\n+          \"patch_sha256\": \"7d86d1f664818b41827da0cd59f0678661a7a132179af312dd5b1c9a6268e0ac\"\n+        },\n+        {\n+          \"ts\": \"2026-02-20T14:43:30.991132Z\",\n+          \"episode_id\": \"6b6ddb5ee674510280b27ef5ec0fd1ea952bd37fe5219b20a401436cc49b330a\",\n+          \"head_sha\": \"12fa54d6612b9850af96591a8b72f9a7375bccaf\",\n+          \"patch_sha256\": \"51418058b65060d53f0aef79cf9093151c3053e71eefe5dc9e979c8dfd5ea404\"\n+        },\n+        {\n+          \"ts\": \"2026-02-20T21:52:31.545973Z\",\n+          \"episode_id\": \"6992ef1d173f95de9b9b407d46c0060ff0c5d2e72bcff50875f1bcc10cafe0cb\",\n+          \"head_sha\": \"12fa54d6612b9850af96591a8b72f9a7375bccaf\",\n+          \"patch_sha256\": \"82da319959d61f024ea6fed3ac7f24578e76fda777db1919074a6166498c2463\"\n+        }\n+      ]\n+    },\n+    {\n+      \"id\": \"az-hp-pipeline-shell-scripts\",\n+      \"title\": \"Pipeline shell scripts use bash with set -euo pipefail\",\n+      \"trigger\": \"When editing or creating shell scripts in the pipeline/ directory\",\n+      \"action\": \"Always include `set -euo pipefail` at the top of bash scripts and use proper error handling with trap statements\",\n+      \"tags\": [\n+        \"bash\",\n+        \"error-handling\",\n+        \"pipeline\"\n+      ],\n+      \"confidence\": 0.7,\n+      \"status\": \"active\",\n+      \"created_at\": \"2026-02-20T00:51:17.517461Z\",\n+      \"updated_at\": \"2026-02-20T21:52:31.545973Z\",\n+      \"evidence\": [\n+        {\n+          \"ts\": \"2026-02-20T00:51:17.517461Z\",\n+          \"episode_id\": \"15e93a4c051522121a704e00ec72f8f276e3f477729fbf7d20005cc42eb7bb38\",\n+          \"head_sha\": \"12fa54d6612b9850af96591a8b72f9a7375bccaf\",\n+          \"patch_sha256\": \"e96515a87eac152e3942d8edf48c8f500e115709082ba6166bdfa1e04ac56ca5\"\n+        },\n+        {\n+          \"ts\": \"2026-02-20T21:52:31.545973Z\",\n+          \"episode_id\": \"6992ef1d173f95de9b9b407d46c0060ff0c5d2e72bcff50875f1bcc10cafe0cb\",\n+          \"head_sha\": \"12fa54d6612b9850af96591a8b72f9a7375bccaf\",\n+          \"patch_sha256\": \"82da319959d61f024ea6fed3ac7f24578e76fda777db1919074a6166498c2463\"\n+        }\n+      ]\n+    },\n+    {\n+      \"id\": \"az-hp-tile-generation\",\n+      \"title\": \"Tile generation pipeline pattern\",\n+      \"trigger\": \"When working with the az-hp geospatial pipeline, specifically tile generation steps\",\n+      \"action\": \"Check pipeline/04_generate_tiles.sh for the tile generation workflow. This project uses a numbered pipeline script convention (01_, 02_, 03_, 04_) in the pipeline/ directory.\",\n+      \"tags\": [\n+        \"az-hp\",\n+        \"geospatial\",\n+        \"pipeline\"\n+      ],\n+      \"confidence\": 0.6,\n+      \"status\": \"active\",\n+      \"created_at\": \"2026-02-20T01:14:48.387480Z\",\n+      \"updated_at\": \"2026-02-20T14:43:30.991132Z\",\n+      \"evidence\": [\n+        {\n+          \"ts\": \"2026-02-20T01:14:48.387480Z\",\n+          \"episode_id\": \"aea43799649d4b3101aa55ac43b3f08ef3ae7614cb3d7ee49ced14feea17a5af\",\n+          \"head_sha\": \"12fa54d6612b9850af96591a8b72f9a7375bccaf\",\n+          \"patch_sha256\": \"7d86d1f664818b41827da0cd59f0678661a7a132179af312dd5b1c9a6268e0ac\"\n+        },\n+        {\n+          \"ts\": \"2026-02-20T14:43:30.991132Z\",\n+          \"episode_id\": \"6b6ddb5ee674510280b27ef5ec0fd1ea952bd37fe5219b20a401436cc49b330a\",\n+          \"head_sha\": \"12fa54d6612b9850af96591a8b72f9a7375bccaf\",\n+          \"patch_sha256\": \"51418058b65060d53f0aef79cf9093151c3053e71eefe5dc9e979c8dfd5ea404\"\n+        }\n+      ]\n+    },\n+    {\n+      \"id\": \"az-hp-tile-generation-gdal\",\n+      \"title\": \"Tile generation uses GDAL utilities\",\n+      \"trigger\": \"When working on map tile generation or the 04_generate_tiles.sh script\",\n+      \"action\": \"Use gdal2tiles.py or gdal_translate for raster tile generation; check that GDAL is available in the environment and handle missing dependencies gracefully\",\n+      \"tags\": [\n+        \"gdal\",\n+        \"geospatial\",\n+        \"pipeline\",\n+        \"tiles\"\n+      ],\n+      \"confidence\": 0.7,\n+      \"status\": \"active\",\n+      \"created_at\": \"2026-02-20T21:52:31.545973Z\",\n+      \"updated_at\": \"2026-02-20T21:52:31.545973Z\",\n+      \"evidence\": [\n+        {\n+          \"ts\": \"2026-02-20T21:52:31.545973Z\",\n+          \"episode_id\": \"6992ef1d173f95de9b9b407d46c0060ff0c5d2e72bcff50875f1bcc10cafe0cb\",\n+          \"head_sha\": \"12fa54d6612b9850af96591a8b72f9a7375bccaf\",\n+          \"patch_sha256\": \"82da319959d61f024ea6fed3ac7f24578e76fda777db1919074a6166498c2463\"\n+        }\n+      ]\n+    },\n+    {\n+      \"id\": \"az-hp-tile-generation-pipeline\",\n+      \"title\": \"Tile generation uses shell script\",\n+      \"trigger\": \"When working with the az-hp map tile pipeline or modifying geographic data processing\",\n+      \"action\": \"Check pipeline/04_generate_tiles.sh for tile generation logic. The pipeline follows a numbered sequence: 03_enrich.py -> 04_generate_tiles.sh.\",\n+      \"tags\": [\n+        \"az-hp\",\n+        \"geospatial\",\n+        \"pipeline\"\n+      ],\n+      \"confidence\": 0.6,\n+      \"status\": \"active\",\n+      \"created_at\": \"2026-02-20T01:03:53.462206Z\",\n+      \"updated_at\": \"2026-02-20T01:03:53.462206Z\",\n+      \"evidence\": [\n+        {\n+          \"ts\": \"2026-02-20T01:03:53.462206Z\",\n+          \"episode_id\": \"08ab15196f535be35da63fa994005d24321037f7926984f9b793966ac7cd117a\",\n+          \"head_sha\": \"12fa54d6612b9850af96591a8b72f9a7375bccaf\",\n+          \"patch_sha256\": \"1d4114763a3cf8de38717b31d0ac30627dbfc7fac9b851a7985b5f6169ef6b99\"\n+        }\n+      ]\n+    },\n+    {\n+      \"id\": \"barrel-export-hooks\",\n+      \"title\": \"Use barrel exports for custom hooks directories\",\n+      \"trigger\": \"When creating multiple custom hooks in a hooks/ directory\",\n+      \"action\": \"Create an index.js barrel file that re-exports all hooks, enabling clean imports like `import { useMap, useMapSources } from './hooks'`\",\n+      \"tags\": [\n+        \"frontend\",\n+        \"imports\",\n+        \"react\"\n+      ],\n+      \"confidence\": 0.8,\n+      \"status\": \"active\",\n+      \"created_at\": \"2026-02-20T03:23:15.037204Z\",\n+      \"updated_at\": \"2026-02-20T03:23:15.037204Z\",\n+      \"evidence\": [\n+        {\n+          \"ts\": \"2026-02-20T03:23:15.037204Z\",\n+          \"episode_id\": \"452f7b6620b2fd5a1cd076d465f95f25e33bc64277721d421a04da798f24464e\",\n+          \"head_sha\": \"12fa54d6612b9850af96591a8b72f9a7375bccaf\",\n+          \"patch_sha256\": \"6507cff21baa7556c8748e2cc86c2f9aadd26665fee07abd00a9ac4bf953b004\"\n+        }\n+      ]\n+    },\n+    {\n+      \"id\": \"frontend-component-extraction\",\n+      \"title\": \"Extract large JSX into dedicated components\",\n+      \"trigger\": \"When App.jsx or any single component exceeds ~200 lines\",\n+      \"action\": \"Extract logical sections into dedicated component files under frontend/src/components/. The project already follows this pattern (e.g., LayerPanel.jsx).\",\n+      \"tags\": [\n+        \"frontend\",\n+        \"react\",\n+        \"refactoring\"\n+      ],\n+      \"confidence\": 0.75,\n+      \"status\": \"active\",\n+      \"created_at\": \"2026-02-20T03:28:01.864128Z\",\n+      \"updated_at\": \"2026-02-20T03:28:01.864128Z\",\n+      \"evidence\": [\n+        {\n+          \"ts\": \"2026-02-20T03:28:01.864128Z\",\n+          \"episode_id\": \"1d03c6ad9c9a99f123cdf8b90388271128ae8ffba87d956a63088f21fb200498\",\n+          \"head_sha\": \"12fa54d6612b9850af96591a8b72f9a7375bccaf\",\n+          \"patch_sha256\": \"992f83d2f73a79f74b3a2114338511b7c737a5e6f66c7b6b6b3c280725902820\"\n+        }\n+      ]\n+    },\n+    {\n+      \"id\": \"instincts-json-sync\",\n+      \"title\": \"Keep instincts.json and INSTINCTS.md in sync\",\n+      \"trigger\": \"When updating instincts or compound memory\",\n+      \"action\": \"Both .loom/compound/instincts.json and .loom/compound/INSTINCTS.md must be updated together. The JSON is the source of truth; the MD is the human-readable view.\",\n+      \"tags\": [\n+        \"compound\",\n+        \"loom\",\n+        \"memory\"\n+      ],\n+      \"confidence\": 0.8,\n+      \"status\": \"active\",\n+      \"created_at\": \"2026-02-20T03:28:01.864128Z\",\n+      \"updated_at\": \"2026-02-20T03:28:01.864128Z\",\n+      \"evidence\": [\n+        {\n+          \"ts\": \"2026-02-20T03:28:01.864128Z\",\n+          \"episode_id\": \"1d03c6ad9c9a99f123cdf8b90388271128ae8ffba87d956a63088f21fb200498\",\n+          \"head_sha\": \"12fa54d6612b9850af96591a8b72f9a7375bccaf\",\n+          \"patch_sha256\": \"992f83d2f73a79f74b3a2114338511b7c737a5e6f66c7b6b6b3c280725902820\"\n+        }\n+      ]\n+    },\n+    {\n+      \"id\": \"makefile-pipeline-orchestration\",\n+      \"title\": \"Makefile orchestrates data pipeline\",\n+      \"trigger\": \"When running or modifying the data pipeline\",\n+      \"action\": \"Use `make` targets to run pipeline steps. Check the Makefile for available targets and their dependencies before running pipeline scripts directly.\",\n+      \"tags\": [\n+        \"make\",\n+        \"orchestration\",\n+        \"pipeline\"\n+      ],\n+      \"confidence\": 0.7,\n+      \"status\": \"active\",\n+      \"created_at\": \"2026-02-20T03:28:01.864128Z\",\n+      \"updated_at\": \"2026-02-20T03:28:01.864128Z\",\n+      \"evidence\": [\n+        {\n+          \"ts\": \"2026-02-20T03:28:01.864128Z\",\n+          \"episode_id\": \"1d03c6ad9c9a99f123cdf8b90388271128ae8ffba87d956a63088f21fb200498\",\n+          \"head_sha\": \"12fa54d6612b9850af96591a8b72f9a7375bccaf\",\n+          \"patch_sha256\": \"992f83d2f73a79f74b3a2114338511b7c737a5e6f66c7b6b6b3c280725902820\"\n+        }\n+      ]\n+    },\n+    {\n+      \"id\": \"makefile-pipeline-targets\",\n+      \"title\": \"Add Makefile targets for pipeline steps\",\n+      \"trigger\": \"When adding new pipeline scripts\",\n+      \"action\": \"Add corresponding Makefile targets so the full pipeline can be run via make commands. Keep targets composable and ordered.\",\n+      \"tags\": [\n+        \"devops\",\n+        \"makefile\",\n+        \"pipeline\"\n+      ],\n+      \"confidence\": 0.75,\n+      \"status\": \"active\",\n+      \"created_at\": \"2026-02-20T03:23:15.037204Z\",\n+      \"updated_at\": \"2026-02-20T03:23:15.037204Z\",\n+      \"evidence\": [\n+        {\n+          \"ts\": \"2026-02-20T03:23:15.037204Z\",\n+          \"episode_id\": \"452f7b6620b2fd5a1cd076d465f95f25e33bc64277721d421a04da798f24464e\",\n+          \"head_sha\": \"12fa54d6612b9850af96591a8b72f9a7375bccaf\",\n+          \"patch_sha256\": \"6507cff21baa7556c8748e2cc86c2f9aadd26665fee07abd00a9ac4bf953b004\"\n+        }\n+      ]\n+    },\n+    {\n+      \"id\": \"react-hook-extraction\",\n+      \"title\": \"Extract large React components into custom hooks\",\n+      \"trigger\": \"When a React component file exceeds ~200 lines with mixed concerns (state, effects, event handlers, rendering)\",\n+      \"action\": \"Extract logical groups into custom hooks (e.g., useMapSources, useMapLayers, useMapInteractions) with a barrel index.js export. Keep the main component as a thin composition layer.\",\n+      \"tags\": [\n+        \"frontend\",\n+        \"react\",\n+        \"refactoring\"\n+      ],\n+      \"confidence\": 0.85,\n+      \"status\": \"active\",\n+      \"created_at\": \"2026-02-20T03:23:15.037204Z\",\n+      \"updated_at\": \"2026-02-20T03:23:15.037204Z\",\n+      \"evidence\": [\n+        {\n+          \"ts\": \"2026-02-20T03:23:15.037204Z\",\n+          \"episode_id\": \"452f7b6620b2fd5a1cd076d465f95f25e33bc64277721d421a04da798f24464e\",\n+          \"head_sha\": \"12fa54d6612b9850af96591a8b72f9a7375bccaf\",\n+          \"patch_sha256\": \"6507cff21baa7556c8748e2cc86c2f9aadd26665fee07abd00a9ac4bf953b004\"\n+        }\n+      ]\n+    },\n+    {\n+      \"id\": \"tile-generation-pipeline\",\n+      \"title\": \"Tile generation uses dedicated shell script\",\n+      \"trigger\": \"When working with the map tile generation step of the pipeline\",\n+      \"action\": \"Check pipeline/04_generate_tiles.sh for tile generation logic. This is a standalone bash script, not part of the Python pipeline scripts.\",\n+      \"tags\": [\n+        \"geospatial\",\n+        \"pipeline\",\n+        \"tiles\"\n+      ],\n+      \"confidence\": 0.65,\n+      \"status\": \"active\",\n+      \"created_at\": \"2026-02-20T03:23:15.037204Z\",\n+      \"updated_at\": \"2026-02-20T03:28:01.864128Z\",\n+      \"evidence\": [\n+        {\n+          \"ts\": \"2026-02-20T03:23:15.037204Z\",\n+          \"episode_id\": \"452f7b6620b2fd5a1cd076d465f95f25e33bc64277721d421a04da798f24464e\",\n+          \"head_sha\": \"12fa54d6612b9850af96591a8b72f9a7375bccaf\",\n+          \"patch_sha256\": \"6507cff21baa7556c8748e2cc86c2f9aadd26665fee07abd00a9ac4bf953b004\"\n+        },\n+        {\n+          \"ts\": \"2026-02-20T03:28:01.864128Z\",\n+          \"episode_id\": \"1d03c6ad9c9a99f123cdf8b90388271128ae8ffba87d956a63088f21fb200498\",\n+          \"head_sha\": \"12fa54d6612b9850af96591a8b72f9a7375bccaf\",\n+          \"patch_sha256\": \"992f83d2f73a79f74b3a2114338511b7c737a5e6f66c7b6b6b3c280725902820\"\n+        }\n+      ]\n+    },\n+    {\n+      \"id\": \"tippecanoe-tile-generation\",\n+      \"title\": \"Use tippecanoe for vector tile generation\",\n+      \"trigger\": \"When generating map tiles from GeoJSON in the az-hp project\",\n+      \"action\": \"Use the 04_generate_tiles.sh script which wraps tippecanoe. Check pipeline/04_generate_tiles.sh for the current tippecanoe flags and layer configuration.\",\n+      \"tags\": [\n+        \"az-hp\",\n+        \"pipeline\",\n+        \"tiles\",\n+        \"tippecanoe\"\n+      ],\n+      \"confidence\": 0.6,\n+      \"status\": \"active\",\n+      \"created_at\": \"2026-02-20T14:50:56.251832Z\",\n+      \"updated_at\": \"2026-02-20T14:50:56.251832Z\",\n+      \"evidence\": [\n+        {\n+          \"ts\": \"2026-02-20T14:50:56.251832Z\",\n+          \"episode_id\": \"e4921c461a96610218c0dd59e32ddd4183f786d1488fb7fabc5343ed65246ec5\",\n+          \"head_sha\": \"12fa54d6612b9850af96591a8b72f9a7375bccaf\",\n+          \"patch_sha256\": \"aa853ee3cda8b401fa071cca9c6dd339149226a29c6eea408fe795e6b30fa799\"\n+        }\n+      ]\n+    }\n+  ]\n }\ndiff --git a/Makefile b/Makefile\nindex 8f1aab5..60bc7fd 100644\n--- a/Makefile\n+++ b/Makefile\n@@ -1,6 +1,6 @@\n-.PHONY: download clip enrich tiles build-frontend all clean\n+.PHONY: download clip enrich tiles basemap build-frontend all clean\n \n-all: download clip enrich tiles build-frontend\n+all: download clip enrich tiles basemap build-frontend\n \n download:\n \t@echo \"=== Downloading data ===\"\n@@ -18,6 +18,12 @@ tiles:\n \t@echo \"=== Generating PMTiles ===\"\n \tbash pipeline/04_generate_tiles.sh\n \n+basemap:\n+\t@echo \"=== Downloading Protomaps basemap ===\"\n+\tpmtiles extract https://build.protomaps.com/$(shell date +%Y%m%d).pmtiles \\\n+\t\tfrontend/public/data/basemap.pmtiles \\\n+\t\t--bbox=-115.5,30.5,-108.0,37.5\n+\n build-frontend:\n \t@echo \"=== Building frontend ===\"\n \tcd frontend && npm run build\n@@ -36,11 +42,12 @@ clean:\n help:\n \t@echo \"AZ Hunt Planner - Makefile commands\"\n \t@echo \"\"\n-\t@echo \"  make all            - Run full pipeline (download, clip, enrich, tiles, build)\"\n+\t@echo \"  make all            - Run full pipeline (download, clip, enrich, tiles, basemap, build)\"\n \t@echo \"  make download       - Download all data sources\"\n \t@echo \"  make clip           - Clip Overture data to Arizona boundary\"\n \t@echo \"  make enrich         - Enrich roads with land ownership and hunt units\"\n \t@echo \"  make tiles          - Generate PMTiles from processed data\"\n+\t@echo \"  make basemap        - Download Protomaps Arizona basemap\"\n \t@echo \"  make build-frontend - Build frontend for production\"\n \t@echo \"  make dev-frontend   - Start frontend development server\"\n \t@echo \"  make clean          - Remove all generated data and build artifacts\"\ndiff --git a/frontend/package-lock.json b/frontend/package-lock.json\nindex b4937ad..8a1a93e 100644\n--- a/frontend/package-lock.json\n+++ b/frontend/package-lock.json\n@@ -8,6 +8,7 @@\n       \"name\": \"frontend\",\n       \"version\": \"0.0.0\",\n       \"dependencies\": {\n+        \"@protomaps/basemaps\": \"^5.7.0\",\n         \"@turf/turf\": \"^7.3.4\",\n         \"maplibre-gl\": \"^5.18.0\",\n         \"pmtiles\": \"^4.4.0\",\n@@ -1124,6 +1125,15 @@\n         \"supercluster\": \"^8.0.1\"\n       }\n     },\n+    \"node_modules/@protomaps/basemaps\": {\n+      \"version\": \"5.7.0\",\n+      \"resolved\": \"https://registry.npmjs.org/@protomaps/basemaps/-/basemaps-5.7.0.tgz\",\n+      \"integrity\": \"sha512-vIInnzVSxHuOcvj1BFGkCjlFxG/9a1GV23t98kGEVcPUM7aEqTnf6loUHTRJYX5eCz+WCO16N0aibr1SLg830Q==\",\n+      \"license\": \"BSD-3-Clause\",\n+      \"bin\": {\n+        \"generate_style\": \"src/cli.ts\"\n+      }\n+    },\n     \"node_modules/@rolldown/pluginutils\": {\n       \"version\": \"1.0.0-rc.3\",\n       \"resolved\": \"https://registry.npmjs.org/@rolldown/pluginutils/-/pluginutils-1.0.0-rc.3.tgz\",\ndiff --git a/frontend/package.json b/frontend/package.json\nindex c8fa239..521fe84 100644\n--- a/frontend/package.json\n+++ b/frontend/package.json\n@@ -10,6 +10,7 @@\n     \"preview\": \"vite preview\"\n   },\n   \"dependencies\": {\n+    \"@protomaps/basemaps\": \"^5.7.0\",\n     \"@turf/turf\": \"^7.3.4\",\n     \"maplibre-gl\": \"^5.18.0\",\n     \"pmtiles\": \"^4.4.0\",\ndiff --git a/frontend/src/App.jsx b/frontend/src/App.jsx\nindex 5f51845..d03d25a 100644\n--- a/frontend/src/App.jsx\n+++ b/frontend/src/App.jsx\n@@ -1,306 +1,27 @@\n-import React, { useEffect, useRef, useState } from 'react'\n-import maplibregl from 'maplibre-gl'\n-import { Protocol } from 'pmtiles'\n+import React, { useRef, useState } from 'react'\n import 'maplibre-gl/dist/maplibre-gl.css'\n+import { useMap } from './hooks/useMap'\n+import { useMapSources } from './hooks/useMapSources'\n+import { useMapLayers } from './hooks/useMapLayers'\n+import { useMapInteractions } from './hooks/useMapInteractions'\n+import { DEFAULT_VISIBILITY } from './config/layers'\n import LayerPanel from './components/LayerPanel'\n import UnitInfoPanel from './components/UnitInfoPanel'\n import './App.css'\n \n-const protocol = new Protocol()\n-maplibregl.addProtocol('pmtiles', protocol.tile)\n-\n-const TILE_BASE = '/data'\n-\n export default function App() {\n-  const mapContainer = useRef(null)\n-  const map = useRef(null)\n-  const [selectedUnit, setSelectedUnit] = useState(null)\n-  const [layers, setLayers] = useState({\n-    roads: true,\n-    landOwnership: true,\n-    huntUnits: true,\n-    water: true,\n-    landCover: false,\n-    buildings: false,\n-    places: true,\n-  })\n+  const mapContainerRef = useRef(null)\n+  const [visibility, setVisibility] = useState(DEFAULT_VISIBILITY)\n \n-  useEffect(() => {\n-    if (map.current) return\n-\n-    map.current = new maplibregl.Map({\n-      container: mapContainer.current,\n-      style: {\n-        version: 8,\n-        sources: {},\n-        layers: [{\n-          id: 'background',\n-          type: 'background',\n-          paint: { 'background-color': '#f0ede6' }\n-        }],\n-        glyphs: 'https://demotiles.maplibre.org/font/{fontstack}/{range}.pbf',\n-      },\n-      center: [-111.75, 34.5],\n-      zoom: 7,\n-      maxBounds: [[-115.5, 30.5], [-108.0, 37.5]],\n-    })\n-\n-    map.current.on('load', () => {\n-      addSources()\n-      addLayers()\n-      addInteractions()\n-    })\n-\n-    return () => map.current?.remove()\n-  }, [])\n-\n-  function addSources() {\n-    const m = map.current\n-\n-    m.addSource('roads', {\n-      type: 'vector',\n-      url: `pmtiles://${TILE_BASE}/roads.pmtiles`,\n-    })\n-    m.addSource('water', {\n-      type: 'vector',\n-      url: `pmtiles://${TILE_BASE}/water.pmtiles`,\n-    })\n-    m.addSource('landcover', {\n-      type: 'vector',\n-      url: `pmtiles://${TILE_BASE}/landcover.pmtiles`,\n-    })\n-    m.addSource('buildings', {\n-      type: 'vector',\n-      url: `pmtiles://${TILE_BASE}/buildings.pmtiles`,\n-    })\n-    m.addSource('places', {\n-      type: 'vector',\n-      url: `pmtiles://${TILE_BASE}/places.pmtiles`,\n-    })\n-    m.addSource('hunt-units', {\n-      type: 'geojson',\n-      data: `${TILE_BASE}/azgfd_gmu.geojson`,\n-    })\n-    m.addSource('land-ownership', {\n-      type: 'geojson',\n-      data: `${TILE_BASE}/blm_sma_az.geojson`,\n-    })\n-  }\n-\n-  function addLayers() {\n-    const m = map.current\n-\n-    m.addLayer({\n-      id: 'landcover-fill',\n-      type: 'fill',\n-      source: 'landcover',\n-      'source-layer': 'landcover',\n-      paint: {\n-        'fill-color': [\n-          'match', ['get', 'subtype'],\n-          'forest', '#2d5a27',\n-          'grass', '#a8c686',\n-          'shrub', '#c4b17c',\n-          'barren', '#d4c5a0',\n-          'wetland', '#6b9e8a',\n-          'crop', '#e8d87c',\n-          '#ddd'\n-        ],\n-        'fill-opacity': 0.4,\n-      },\n-    })\n-\n-    m.addLayer({\n-      id: 'land-ownership-fill',\n-      type: 'fill',\n-      source: 'land-ownership',\n-      paint: {\n-        'fill-color': [\n-          'match', ['get', 'ADMIN_AGENCY_CODE'],\n-          'BLM', '#ffc107',\n-          'FS', '#4caf50',\n-          'NPS', '#8bc34a',\n-          'FWS', '#00bcd4',\n-          'BOR', '#2196f3',\n-          'DOD', '#f44336',\n-          'STP', '#9c27b0',\n-          '#999'\n-        ],\n-        'fill-opacity': 0.25,\n-      },\n-    })\n-    m.addLayer({\n-      id: 'land-ownership-outline',\n-      type: 'line',\n-      source: 'land-ownership',\n-      paint: {\n-        'line-color': '#666',\n-        'line-width': 0.5,\n-        'line-opacity': 0.5,\n-      },\n-    })\n-\n-    m.addLayer({\n-      id: 'water-fill',\n-      type: 'fill',\n-      source: 'water',\n-      'source-layer': 'water',\n-      paint: {\n-        'fill-color': '#a4cce4',\n-        'fill-opacity': 0.7,\n-      },\n-    })\n-\n-    m.addLayer({\n-      id: 'hunt-units-outline',\n-      type: 'line',\n-      source: 'hunt-units',\n-      paint: {\n-        'line-color': '#d32f2f',\n-        'line-width': 2,\n-        'line-dasharray': [4, 2],\n-      },\n-    })\n-    m.addLayer({\n-      id: 'hunt-units-fill',\n-      type: 'fill',\n-      source: 'hunt-units',\n-      paint: {\n-        'fill-color': '#d32f2f',\n-        'fill-opacity': 0.05,\n-      },\n-    })\n-    m.addLayer({\n-      id: 'hunt-units-labels',\n-      type: 'symbol',\n-      source: 'hunt-units',\n-      layout: {\n-        'text-field': ['get', 'GMUNAME'],\n-        'text-size': 14,\n-        'text-font': ['Open Sans Bold'],\n-      },\n-      paint: {\n-        'text-color': '#b71c1c',\n-        'text-halo-color': '#fff',\n-        'text-halo-width': 2,\n-      },\n-    })\n-\n-    m.addLayer({\n-      id: 'roads-line',\n-      type: 'line',\n-      source: 'roads',\n-      'source-layer': 'roads',\n-      paint: {\n-        'line-color': [\n-          'match', ['get', 'land_status'],\n-          'public_usfs', '#2e7d32',\n-          'public_blm', '#f9a825',\n-          'public_nps', '#558b2f',\n-          'public_fws', '#00897b',\n-          'public_bor', '#1565c0',\n-          'restricted_military', '#c62828',\n-          'state_trust', '#7b1fa2',\n-          '#e65100'\n-        ],\n-        'line-width': [\n-          'match', ['get', 'class'],\n-          'primary', 3,\n-          'secondary', 2.5,\n-          'tertiary', 2,\n-          'track', 1.5,\n-          'path', 1,\n-          'footway', 1,\n-          1.5\n-        ],\n-        'line-opacity': 0.8,\n-      },\n-    })\n-\n-    m.addLayer({\n-      id: 'buildings-fill',\n-      type: 'fill',\n-      source: 'buildings',\n-      'source-layer': 'buildings',\n-      minzoom: 12,\n-      paint: {\n-        'fill-color': '#bbb',\n-        'fill-opacity': 0.6,\n-        'fill-outline-color': '#888',\n-      },\n-    })\n-\n-    m.addLayer({\n-      id: 'places-circle',\n-      type: 'circle',\n-      source: 'places',\n-      'source-layer': 'places',\n-      paint: {\n-        'circle-radius': 5,\n-        'circle-color': '#1565c0',\n-        'circle-stroke-width': 1.5,\n-        'circle-stroke-color': '#fff',\n-      },\n-    })\n-  }\n-\n-  function addInteractions() {\n-    const m = map.current\n-\n-    m.on('click', 'hunt-units-fill', (e) => {\n-      const props = e.features[0].properties\n-      setSelectedUnit(props)\n-    })\n-\n-    for (const layer of ['hunt-units-fill', 'roads-line', 'places-circle']) {\n-      m.on('mouseenter', layer, () => {\n-        m.getCanvas().style.cursor = 'pointer'\n-      })\n-      m.on('mouseleave', layer, () => {\n-        m.getCanvas().style.cursor = ''\n-      })\n-    }\n-\n-    m.on('click', 'roads-line', (e) => {\n-      const props = e.features[0].properties\n-      new maplibregl.Popup()\n-        .setLngLat(e.lngLat)\n-        .setHTML(`\n-          <strong>${props.road_name || 'Unnamed road'}</strong><br/>\n-          Class: ${props.class || 'unknown'}<br/>\n-          Surface: ${props.surface || 'unknown'}<br/>\n-          Land: ${props.land_status || 'unknown'}<br/>\n-          Unit: ${props.GMUNAME || 'N/A'}\n-        `)\n-        .addTo(m)\n-    })\n-  }\n-\n-  useEffect(() => {\n-    if (!map.current?.isStyleLoaded()) return\n-    const layerMap = {\n-      roads: ['roads-line'],\n-      landOwnership: ['land-ownership-fill', 'land-ownership-outline'],\n-      huntUnits: ['hunt-units-outline', 'hunt-units-fill', 'hunt-units-labels'],\n-      water: ['water-fill'],\n-      landCover: ['landcover-fill'],\n-      buildings: ['buildings-fill'],\n-      places: ['places-circle'],\n-    }\n-    for (const [key, ids] of Object.entries(layerMap)) {\n-      const visibility = layers[key] ? 'visible' : 'none'\n-      ids.forEach(id => {\n-        if (map.current.getLayer(id)) {\n-          map.current.setLayoutProperty(id, 'visibility', visibility)\n-        }\n-      })\n-    }\n-  }, [layers])\n+  const { map, isLoaded } = useMap(mapContainerRef)\n+  useMapSources(map, isLoaded)\n+  useMapLayers(map, isLoaded, visibility)\n+  const { selectedUnit, setSelectedUnit } = useMapInteractions(map, isLoaded)\n \n   return (\n     <div className=\"app\">\n-      <div ref={mapContainer} className=\"map-container\" />\n-      <LayerPanel layers={layers} setLayers={setLayers} />\n+      <div ref={mapContainerRef} className=\"map-container\" />\n+      <LayerPanel layers={visibility} setLayers={setVisibility} />\n       {selectedUnit && (\n         <UnitInfoPanel\n           unit={selectedUnit}\ndiff --git a/frontend/src/components/LayerPanel.jsx b/frontend/src/components/LayerPanel.jsx\nindex 93f916d..9a2cd67 100644\n--- a/frontend/src/components/LayerPanel.jsx\n+++ b/frontend/src/components/LayerPanel.jsx\n@@ -4,9 +4,6 @@ const LAYER_CONFIG = [\n   { key: 'huntUnits', label: 'Hunt Units', color: '#d32f2f' },\n   { key: 'roads', label: 'Roads & Trails', color: '#555' },\n   { key: 'landOwnership', label: 'Land Ownership', color: '#4caf50' },\n-  { key: 'water', label: 'Water', color: '#a4cce4' },\n-  { key: 'landCover', label: 'Land Cover', color: '#2d5a27' },\n-  { key: 'buildings', label: 'Buildings', color: '#bbb' },\n   { key: 'places', label: 'Trailheads / POIs', color: '#1565c0' },\n ]\n \ndiff --git a/pipeline/01_download.py b/pipeline/01_download.py\nindex cadd417..bc5fa2e 100644\n--- a/pipeline/01_download.py\n+++ b/pipeline/01_download.py\n@@ -7,6 +7,7 @@ import duckdb\n import httpx\n import json\n import zipfile\n+import geopandas as gpd\n from pipeline.utils import (\n     AZ_BBOX,\n     OVERTURE_S3_BASE,\n@@ -15,13 +16,25 @@ from pipeline.utils import (\n     BLM_SMA_BASE_URL,\n     BLM_SMA_LAYERS,\n     AZ_BOUNDARY_URL,\n-    USFS_FOREST_URL,\n )\n \n RAW_DIR.mkdir(parents=True, exist_ok=True)\n \n \n+def file_exists(path: Path, min_size_mb: float = 0.001) -> bool:\n+    if not path.exists():\n+        return False\n+    if path.stat().st_size < min_size_mb * 1_000_000:\n+        return False\n+    return True\n+\n+\n def download_overture_transportation():\n+    output_path = RAW_DIR / \"overture_transportation_az.parquet\"\n+    if file_exists(output_path, min_size_mb=1):\n+        print(\"  Transportation already downloaded, skipping.\")\n+        return\n+\n     print(\"Downloading Overture transportation segments...\")\n     con = duckdb.connect()\n     con.execute(\"INSTALL spatial; LOAD spatial;\")\n@@ -40,69 +53,18 @@ def download_overture_transportation():\n               AND bbox.xmax <= {AZ_BBOX['xmax']}\n               AND bbox.ymin >= {AZ_BBOX['ymin']}\n               AND bbox.ymax <= {AZ_BBOX['ymax']}\n-        ) TO '{RAW_DIR}/overture_transportation_az.parquet'\n+        ) TO '{output_path}'\n         (FORMAT PARQUET);\n     \"\"\")\n     print(\"  Transportation segments saved.\")\n \n \n-def download_overture_base_layers():\n-    con = duckdb.connect()\n-    con.execute(\"INSTALL spatial; LOAD spatial;\")\n-    con.execute(\"INSTALL httpfs; LOAD httpfs;\")\n-    con.execute(\"SET s3_region = 'us-west-2';\")\n-\n-    base_types = [\n-        (\"land_use\", \"id, geometry, subtype, class, names\"),\n-        (\"land_cover\", \"id, geometry, subtype\"),\n-        (\"land\", \"id, geometry, subtype, class, names, elevation\"),\n-        (\"water\", \"id, geometry, subtype, class, names, is_intermittent\"),\n-    ]\n-\n-    for feature_type, columns in base_types:\n-        print(f\"Downloading Overture base/{feature_type}...\")\n-        con.execute(f\"\"\"\n-            COPY (\n-                SELECT {columns}\n-                FROM read_parquet(\n-                    '{OVERTURE_S3_BASE}/theme=base/type={feature_type}/*',\n-                    hive_partitioning=true\n-                )\n-                WHERE bbox.xmin >= {AZ_BBOX['xmin']}\n-                  AND bbox.xmax <= {AZ_BBOX['xmax']}\n-                  AND bbox.ymin >= {AZ_BBOX['ymin']}\n-                  AND bbox.ymax <= {AZ_BBOX['ymax']}\n-            ) TO '{RAW_DIR}/overture_{feature_type}_az.parquet'\n-            (FORMAT PARQUET);\n-        \"\"\")\n-        print(f\"  {feature_type} saved.\")\n-\n-\n-def download_overture_buildings():\n-    print(\"Downloading Overture buildings...\")\n-    con = duckdb.connect()\n-    con.execute(\"INSTALL spatial; LOAD spatial;\")\n-    con.execute(\"INSTALL httpfs; LOAD httpfs;\")\n-    con.execute(\"SET s3_region = 'us-west-2';\")\n-\n-    con.execute(f\"\"\"\n-        COPY (\n-            SELECT id, geometry, subtype, class, names, height, num_floors\n-            FROM read_parquet(\n-                '{OVERTURE_S3_BASE}/theme=buildings/type=building/*',\n-                hive_partitioning=true\n-            )\n-            WHERE bbox.xmin >= {AZ_BBOX['xmin']}\n-              AND bbox.xmax <= {AZ_BBOX['xmax']}\n-              AND bbox.ymin >= {AZ_BBOX['ymin']}\n-              AND bbox.ymax <= {AZ_BBOX['ymax']}\n-        ) TO '{RAW_DIR}/overture_buildings_az.parquet'\n-        (FORMAT PARQUET);\n-    \"\"\")\n-    print(\"  Buildings saved.\")\n-\n-\n def download_overture_places():\n+    output_path = RAW_DIR / \"overture_places_az.parquet\"\n+    if file_exists(output_path, min_size_mb=1):\n+        print(\"  Places already downloaded, skipping.\")\n+        return\n+\n     print(\"Downloading Overture places...\")\n     con = duckdb.connect()\n     con.execute(\"INSTALL spatial; LOAD spatial;\")\n@@ -120,23 +82,33 @@ def download_overture_places():\n               AND bbox.xmax <= {AZ_BBOX['xmax']}\n               AND bbox.ymin >= {AZ_BBOX['ymin']}\n               AND bbox.ymax <= {AZ_BBOX['ymax']}\n-        ) TO '{RAW_DIR}/overture_places_az.parquet'\n+        ) TO '{output_path}'\n         (FORMAT PARQUET);\n     \"\"\")\n     print(\"  Places saved.\")\n \n \n def download_azgfd_gmus():\n+    output_path = RAW_DIR / \"azgfd_gmu.geojson\"\n+    if file_exists(output_path, min_size_mb=1):\n+        print(\"  GMU boundaries already downloaded, skipping.\")\n+        return\n+\n     print(\"Downloading AZGFD Game Management Unit boundaries...\")\n     with httpx.Client(timeout=120, follow_redirects=True) as client:\n         response = client.get(AZGFD_GMU_URL)\n         response.raise_for_status()\n-        with open(RAW_DIR / \"azgfd_gmu.geojson\", \"w\") as f:\n+        with open(output_path, \"w\") as f:\n             f.write(response.text)\n     print(\"  GMU boundaries saved.\")\n \n \n def download_blm_sma():\n+    output_path = RAW_DIR / \"blm_sma_az.geojson\"\n+    if file_exists(output_path, min_size_mb=0.01):\n+        print(\"  BLM SMA already downloaded, skipping.\")\n+        return\n+\n     print(\"Downloading BLM Surface Management Agency data for Arizona...\")\n     all_features = []\n     page_size = 1000\n@@ -190,13 +162,17 @@ def download_blm_sma():\n                 offset += page_size\n \n     geojson = {\"type\": \"FeatureCollection\", \"features\": all_features}\n-    with open(RAW_DIR / \"blm_sma_az.geojson\", \"w\") as f:\n+    with open(output_path, \"w\") as f:\n         json.dump(geojson, f)\n     print(f\"  BLM SMA saved ({len(all_features)} features).\")\n \n \n def download_az_boundary():\n-    import geopandas as gpd\n+    output_path = RAW_DIR / \"az_boundary.geojson\"\n+    if file_exists(output_path, min_size_mb=0.001):\n+        print(\"  Arizona boundary already downloaded, skipping.\")\n+        return\n+\n     print(\"Downloading Arizona state boundary...\")\n     zip_path = RAW_DIR / \"cb_2022_us_state_500k.zip\"\n     extract_dir = RAW_DIR / \"census_states\"\n@@ -218,7 +194,7 @@ def download_az_boundary():\n     states_gdf = gpd.read_file(shp_files[0])\n     az_gdf = states_gdf[states_gdf[\"STUSPS\"] == \"AZ\"]\n     az_gdf = az_gdf.to_crs(\"EPSG:4326\")\n-    az_gdf.to_file(RAW_DIR / \"az_boundary.geojson\", driver=\"GeoJSON\")\n+    az_gdf.to_file(output_path, driver=\"GeoJSON\")\n \n     zip_path.unlink()\n     for f in extract_dir.glob(\"*\"):\n@@ -227,25 +203,6 @@ def download_az_boundary():\n     print(\"  Arizona boundary saved.\")\n \n \n-def download_usfs_forests():\n-    print(\"Downloading USFS Administrative Forest boundaries...\")\n-    zip_path = RAW_DIR / \"usfs_forests.zip\"\n-    extract_dir = RAW_DIR / \"usfs_forests\"\n-\n-    with httpx.Client(timeout=300) as client:\n-        response = client.get(USFS_FOREST_URL)\n-        response.raise_for_status()\n-        with open(zip_path, \"wb\") as f:\n-            f.write(response.content)\n-\n-    extract_dir.mkdir(exist_ok=True)\n-    with zipfile.ZipFile(zip_path, \"r\") as zf:\n-        zf.extractall(extract_dir)\n-\n-    zip_path.unlink()\n-    print(\"  USFS forest boundaries saved.\")\n-\n-\n def main():\n     print(\"=\" * 60)\n     print(\"AZ Hunt Planner - Data Download Pipeline\")\n@@ -254,10 +211,7 @@ def main():\n     download_az_boundary()\n     download_azgfd_gmus()\n     download_blm_sma()\n-    download_usfs_forests()\n     download_overture_transportation()\n-    download_overture_base_layers()\n-    download_overture_buildings()\n     download_overture_places()\n \n     print(\"=\" * 60)\ndiff --git a/pipeline/02_clip_arizona.py b/pipeline/02_clip_arizona.py\nindex 3ac5573..8ac8c2b 100644\n--- a/pipeline/02_clip_arizona.py\n+++ b/pipeline/02_clip_arizona.py\n@@ -9,8 +9,7 @@ from pipeline.utils import RAW_DIR, PROCESSED_DIR\n \n PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n \n-# Threshold for skipping clip - files larger than this are just copied\n-LARGE_LAYER_THRESHOLD = 100_000_000  # 100 MB\n+LARGE_LAYER_THRESHOLD = 100_000_000\n \n \n def load_az_boundary():\n@@ -27,7 +26,10 @@ def clip_layer(input_name: str, output_name: str, az_boundary: gpd.GeoDataFrame)\n         print(f\"  Skipping {input_name} (not found)\")\n         return\n \n-    # Skip clip for large files - just copy them\n+    if output_path.exists():\n+        print(f\"  {output_name} already exists, skipping.\")\n+        return\n+\n     file_size = input_path.stat().st_size\n     if file_size > LARGE_LAYER_THRESHOLD:\n         print(f\"  Copying {input_name} ({file_size / 1_000_000:.1f} MB - too large for clip)...\")\n@@ -35,7 +37,6 @@ def clip_layer(input_name: str, output_name: str, az_boundary: gpd.GeoDataFrame)\n         print(f\"    Copied without clipping\")\n         return\n \n-    # Normal clip for smaller layers\n     print(f\"  Clipping {input_name} ({file_size / 1_000_000:.1f} MB)...\")\n     gdf = gpd.read_parquet(input_path)\n     gdf = gdf.set_crs(\"EPSG:4326\", allow_override=True)\n@@ -60,11 +61,6 @@ def main():\n \n     layers = [\n         (\"overture_transportation_az\", \"overture_transportation_clipped\"),\n-        (\"overture_land_use_az\", \"overture_land_use_clipped\"),\n-        (\"overture_land_cover_az\", \"overture_land_cover_clipped\"),\n-        (\"overture_land_az\", \"overture_land_clipped\"),\n-        (\"overture_water_az\", \"overture_water_clipped\"),\n-        (\"overture_buildings_az\", \"overture_buildings_clipped\"),\n         (\"overture_places_az\", \"overture_places_clipped\"),\n     ]\n \ndiff --git a/pipeline/03_enrich.py b/pipeline/03_enrich.py\nindex 757b462..cbd1c35 100644\n--- a/pipeline/03_enrich.py\n+++ b/pipeline/03_enrich.py\n@@ -17,6 +17,11 @@ PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n \n \n def enrich_roads():\n+    output_path = PROCESSED_DIR / \"roads_enriched.parquet\"\n+    if output_path.exists() and output_path.stat().st_size > 1_000_000:\n+        print(\"Roads already enriched, skipping.\")\n+        return\n+\n     print(\"Enriching roads with land ownership and hunt unit data...\")\n \n     print(\"  Loading roads...\")\n@@ -121,6 +126,11 @@ def enrich_roads():\n \n \n def filter_hunt_pois():\n+    output_path = PROCESSED_DIR / \"places_hunt.parquet\"\n+    if output_path.exists() and output_path.stat().st_size > 10_000:\n+        print(\"Places already filtered, skipping.\")\n+        return\n+\n     print(\"Filtering hunt-relevant POIs...\")\n \n     print(\"  Loading places...\")\n@@ -173,15 +183,15 @@ def prepare_static_layers():\n     gmu_gdf = gpd.read_file(RAW_DIR / \"azgfd_gmu.geojson\")\n     keep_cols = [\"GMUNAME\", \"REG_NAME\", \"ACRES\", \"LANDOWN\", \"HUNT\", \"AGFDLink\", \"geometry\"]\n     gmu_filtered = gmu_gdf[[c for c in keep_cols if c in gmu_gdf.columns]]\n-    gmu_filtered.to_file(frontend_data / \"azgfd_gmu.geojson\", driver=\"GeoJSON\")\n+    gmu_filtered.to_file(PROCESSED_DIR / \"hunt_units.geojson\", driver=\"GeoJSON\")\n \n     print(\"  Copying BLM SMA...\")\n     sma_gdf = gpd.read_file(RAW_DIR / \"blm_sma_az.geojson\")\n     keep_cols = [\"ADMIN_AGENCY_CODE\", \"ADMIN_UNIT_NAME\", \"ADMIN_DEPT_CODE\", \"geometry\"]\n     sma_filtered = sma_gdf[[c for c in keep_cols if c in sma_gdf.columns]]\n-    sma_filtered.to_file(frontend_data / \"blm_sma_az.geojson\", driver=\"GeoJSON\")\n+    sma_filtered.to_file(PROCESSED_DIR / \"land_ownership.geojson\", driver=\"GeoJSON\")\n \n-    print(\"  Static layers saved.\")\n+    print(\"  Static layers saved to processed/ for PMTiles generation.\")\n \n \n def main():\ndiff --git a/pipeline/04_generate_tiles.sh b/pipeline/04_generate_tiles.sh\nindex ee781dd..f4e527b 100755\n--- a/pipeline/04_generate_tiles.sh\n+++ b/pipeline/04_generate_tiles.sh\n@@ -17,102 +17,90 @@ echo \"============================================\"\n \n cd \"$PROJECT_DIR\"\n \n-echo \"Converting Parquet layers to GeoJSON...\"\n-uv run python -c \"\n-import geopandas as gpd\n-from pathlib import Path\n-\n-processed_dir = Path('$PROCESSED_DIR')\n-layers = [\n-    'roads_enriched',\n-    'places_hunt',\n-    'overture_water_clipped',\n-    'overture_land_cover_clipped',\n-    'overture_buildings_clipped',\n-]\n-\n-for layer in layers:\n-    parquet_path = processed_dir / f'{layer}.parquet'\n-    if parquet_path.exists():\n-        print(f'Converting {layer}...')\n-        gdf = gpd.read_parquet(parquet_path)\n-        geojson_path = processed_dir / f'{layer}.geojson'\n-        gdf.to_file(geojson_path, driver='GeoJSON')\n-        print(f'  {layer}: {len(gdf)} features')\n-    else:\n-        print(f'Skipping {layer} (not found)')\n-\"\n-\n-echo \"\"\n echo \"Generating PMTiles with tippecanoe...\"\n+echo \"  (Streaming parquet \u2192 tippecanoe via process substitution)\"\n+echo \"\"\n \n-echo \"  Roads...\"\n-tippecanoe \\\n-    -o \"$TILES_DIR/roads.pmtiles\" \\\n-    -l roads \\\n-    --minimum-zoom=6 \\\n-    --maximum-zoom=14 \\\n-    --drop-densest-as-needed \\\n-    --extend-zooms-if-still-dropping \\\n-    --force \\\n-    \"$PROCESSED_DIR/roads_enriched.geojson\" \\\n-    2>/dev/null || echo \"    Warning: roads tile generation had issues\"\n-\n-echo \"  Places...\"\n-if [ -f \"$PROCESSED_DIR/places_hunt.geojson\" ]; then\n+generate_tiles_parquet() {\n+    local name=$1\n+    local source_layer=$2\n+    local minzoom=$3\n+    local maxzoom=$4\n+    local extra_opts=$5\n+    local input_path=\"$PROCESSED_DIR/${name}.parquet\"\n+    local output_path=\"$TILES_DIR/${source_layer}.pmtiles\"\n+    \n+    if [ ! -f \"$input_path\" ]; then\n+        echo \"  Skipping $name (parquet not found)\"\n+        return 1\n+    fi\n+    \n+    echo \"  $name...\"\n     tippecanoe \\\n-        -o \"$TILES_DIR/places.pmtiles\" \\\n-        -l places \\\n-        --minimum-zoom=8 \\\n-        --maximum-zoom=14 \\\n-        -r1 \\\n+        -o \"$output_path\" \\\n+        -l \"$source_layer\" \\\n+        --minimum-zoom=$minzoom \\\n+        --maximum-zoom=$maxzoom \\\n+        $extra_opts \\\n         --force \\\n-        \"$PROCESSED_DIR/places_hunt.geojson\" \\\n-        2>/dev/null || echo \"    Warning: places tile generation had issues\"\n-fi\n+        <(ogr2ogr -f GeoJSONSeq /vsistdout/ \"$input_path\" 2>/dev/null) \\\n+        2>&1 | grep -E \"(features|Warning|Error)\" || true\n+}\n \n-echo \"  Water...\"\n-if [ -f \"$PROCESSED_DIR/overture_water_clipped.geojson\" ]; then\n+generate_tiles_geojson() {\n+    local name=$1\n+    local source_layer=$2\n+    local minzoom=$3\n+    local maxzoom=$4\n+    local extra_opts=$5\n+    local input_path=\"$PROCESSED_DIR/${name}.geojson\"\n+    local output_path=\"$TILES_DIR/${source_layer}.pmtiles\"\n+    \n+    if [ ! -f \"$input_path\" ]; then\n+        echo \"  Skipping $name (geojson not found)\"\n+        return 1\n+    fi\n+    \n+    echo \"  $name...\"\n     tippecanoe \\\n-        -o \"$TILES_DIR/water.pmtiles\" \\\n-        -l water \\\n-        --minimum-zoom=6 \\\n-        --maximum-zoom=14 \\\n-        --coalesce-densest-as-needed \\\n+        -o \"$output_path\" \\\n+        -l \"$source_layer\" \\\n+        --minimum-zoom=$minzoom \\\n+        --maximum-zoom=$maxzoom \\\n+        $extra_opts \\\n         --force \\\n-        \"$PROCESSED_DIR/overture_water_clipped.geojson\" \\\n-        2>/dev/null || echo \"    Warning: water tile generation had issues\"\n-fi\n+        \"$input_path\" \\\n+        2>&1 | grep -E \"(features|Warning|Error)\" || true\n+}\n \n-echo \"  Land cover...\"\n-if [ -f \"$PROCESSED_DIR/overture_land_cover_clipped.geojson\" ]; then\n-    tippecanoe \\\n-        -o \"$TILES_DIR/landcover.pmtiles\" \\\n-        -l landcover \\\n-        --minimum-zoom=4 \\\n-        --maximum-zoom=12 \\\n-        --coalesce-densest-as-needed \\\n-        --force \\\n-        \"$PROCESSED_DIR/overture_land_cover_clipped.geojson\" \\\n-        2>/dev/null || echo \"    Warning: landcover tile generation had issues\"\n-fi\n+echo \"Starting parallel tile generation...\"\n \n-echo \"  Buildings...\"\n-if [ -f \"$PROCESSED_DIR/overture_buildings_clipped.geojson\" ]; then\n-    tippecanoe \\\n-        -o \"$TILES_DIR/buildings.pmtiles\" \\\n-        -l buildings \\\n-        --minimum-zoom=12 \\\n-        --maximum-zoom=14 \\\n-        --drop-densest-as-needed \\\n-        --force \\\n-        \"$PROCESSED_DIR/overture_buildings_clipped.geojson\" \\\n-        2>/dev/null || echo \"    Warning: buildings tile generation had issues\"\n-fi\n+generate_tiles_parquet \"roads_enriched\" \"roads\" 6 14 \"--drop-densest-as-needed --extend-zooms-if-still-dropping\" &\n+PID1=$!\n+\n+generate_tiles_parquet \"places_hunt\" \"places\" 8 14 \"-r1\" &\n+PID2=$!\n+\n+generate_tiles_geojson \"hunt_units\" \"hunt-units\" 6 14 \"--no-tile-size-limit\" &\n+PID3=$!\n+\n+generate_tiles_geojson \"land_ownership\" \"land-ownership\" 8 14 \"--drop-densest-as-needed --coalesce-densest-as-needed\" &\n+PID4=$!\n+\n+echo \"Waiting for tile generation to complete...\"\n+wait $PID1 || echo \"  roads had issues\"\n+wait $PID2 || echo \"  places had issues\"\n+wait $PID3 || echo \"  hunt-units had issues\"\n+wait $PID4 || echo \"  land-ownership had issues\"\n \n echo \"\"\n echo \"Copying PMTiles to frontend...\"\n-cp \"$TILES_DIR\"/*.pmtiles \"$FRONTEND_DATA/\" 2>/dev/null || echo \"  No PMTiles to copy\"\n+for f in roads places hunt-units land-ownership; do\n+    if [ -f \"$TILES_DIR/${f}.pmtiles\" ]; then\n+        cp \"$TILES_DIR/${f}.pmtiles\" \"$FRONTEND_DATA/\"\n+        echo \"  Copied ${f}.pmtiles\"\n+    fi\n+done\n \n echo \"\"\n echo \"============================================\"\n",
    "patch_omitted": false,
    "patch_sha256": "4758831ff0a1396b1cde4ca71a0afb774aea286cc4a5c7f53a7ea400fbbc3b53"
  },
  "observations": {
    "cursor": {
      "end_count": 7091,
      "end_offset_bytes": 1621461,
      "file_prefix_sha256": "ece996cba6fe744bc1616888106ab8d261ecdad568065f5b121d9611ea87441d",
      "reset_detected": false,
      "start_count": 7088,
      "start_offset_bytes": 1620959,
      "tail_sha256": "c14589d94ca9b36440cee03e38abf234a2bb61893a9a746dfaa088feeaf6b3de"
    },
    "included": [
      {
        "id": "b044399e-c22d-4675-8722-1ded706493b0",
        "properties": {
          "keys": [
            "file",
            "event"
          ]
        },
        "sessionID": null,
        "ts": "2026-02-20T21:52:31.385Z",
        "type": "file.watcher.updated"
      },
      {
        "id": "9f241960-7d3a-4c16-9fc6-b760a2075ea9",
        "properties": {
          "keys": [
            "file",
            "event"
          ]
        },
        "sessionID": null,
        "ts": "2026-02-20T21:52:31.459Z",
        "type": "file.watcher.updated"
      },
      {
        "id": "6cc78685-70f1-4d16-8741-cdef751043be",
        "properties": {
          "keys": [
            "message",
            "variant",
            "duration"
          ]
        },
        "sessionID": null,
        "ts": "2026-02-20T21:52:31.585Z",
        "type": "tui.toast.show"
      }
    ],
    "omitted": false
  },
  "proposals": {
    "instinct_candidates": [
      {
        "action": "Always include `set -euo pipefail` at the top of pipeline shell scripts and use explicit error handling for gdal/ogr commands",
        "confidence": 0.7,
        "id": "az-hp-pipeline-shell-scripts",
        "tags": [
          "pipeline",
          "shell",
          "bash"
        ],
        "title": "Pipeline shell scripts use bash with set -euo pipefail",
        "trigger": "When editing or creating shell scripts in the pipeline/ directory"
      },
      {
        "action": "Break large components into smaller files under frontend/src/components/ and import them back. This session reduced App.jsx by ~280 lines by extracting components.",
        "confidence": 0.75,
        "id": "az-hp-frontend-component-extraction",
        "tags": [
          "frontend",
          "react",
          "components"
        ],
        "title": "Extract large JSX blocks into separate component files",
        "trigger": "When App.jsx or any single component file exceeds ~200 lines"
      },
      {
        "action": "Update the Makefile targets to reflect changes in pipeline scripts (01_download, 02_clip, 03_enrich, 04_generate_tiles). The Makefile is the canonical entry point for running pipeline stages.",
        "confidence": 0.8,
        "id": "az-hp-makefile-pipeline-targets",
        "tags": [
          "pipeline",
          "makefile",
          "build"
        ],
        "title": "Makefile orchestrates the numbered pipeline steps",
        "trigger": "When adding or modifying pipeline steps"
      },
      {
        "action": "The download script was simplified significantly (~80 lines removed). Keep it focused on downloading raw data; transformation logic belongs in later pipeline stages.",
        "confidence": 0.65,
        "id": "az-hp-download-script-simplification",
        "tags": [
          "pipeline",
          "python",
          "data"
        ],
        "title": "Keep download scripts focused on fetching data",
        "trigger": "When modifying pipeline/01_download.py"
      }
    ],
    "skill_candidates": []
  },
  "triage": {
    "notes": "",
    "status": "accepted",
    "tags": []
  },
  "version": 1
}
